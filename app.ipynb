{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97508ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Processing file1.pdf...\n",
      "[✓] Text extracted to outputs\\file1_extracted_text.txt\n",
      "[*] Converting PDF to images using PyMuPDF...\n",
      "[✓] Saved: outputs\\file1_pages\\page_1.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_2.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_3.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_4.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_5.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_6.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_7.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_8.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_9.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_10.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_11.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_12.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_13.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_14.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_15.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_16.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_17.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_18.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_19.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_20.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_21.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_22.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_23.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_24.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_25.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_26.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_27.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_28.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_29.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_30.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_31.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_32.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_33.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_34.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_35.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_36.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_37.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_38.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_39.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_40.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_41.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_42.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_43.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_44.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_45.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_46.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_47.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_48.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_49.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_50.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_51.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_52.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_53.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_54.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_55.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_56.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_57.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_58.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_59.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_60.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_61.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_62.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_63.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_64.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_65.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_66.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_67.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_68.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_69.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_70.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_71.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_72.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_73.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_74.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_75.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_76.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_77.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_78.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_79.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_80.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_81.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_82.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_83.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_84.png\n",
      "[✓] Saved: outputs\\file1_pages\\page_85.png\n",
      "[*] Running OCR on page images...\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_1.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_10.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_11.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_12.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_13.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_14.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_15.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_16.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_17.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_18.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_19.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_2.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_20.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_21.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_22.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_23.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_24.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_25.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_26.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_27.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_28.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_29.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_3.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_30.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_31.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_32.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_33.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_34.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_35.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_36.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_37.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_38.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_39.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_4.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_40.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_41.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_42.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_43.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_44.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_45.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_46.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_47.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_48.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_49.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_5.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_50.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_51.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_52.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_53.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_54.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_55.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_56.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_57.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_58.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_59.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_6.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_60.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_61.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_62.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_63.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_64.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_65.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_66.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_67.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_68.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_69.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_7.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_70.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_71.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_72.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_73.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_74.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_75.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_76.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_77.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_78.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_79.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_8.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_80.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_81.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_82.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_83.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_84.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_85.txt\n",
      "[✓] OCR saved: outputs\\file1_ocr\\page_9.txt\n",
      "[✓] Finished processing file1.pdf\n",
      "\n",
      "[*] Processing file2.pdf...\n",
      "[✓] Text extracted to outputs\\file2_extracted_text.txt\n",
      "[*] Converting PDF to images using PyMuPDF...\n",
      "[✓] Saved: outputs\\file2_pages\\page_1.png\n",
      "[✓] Saved: outputs\\file2_pages\\page_2.png\n",
      "[✓] Saved: outputs\\file2_pages\\page_3.png\n",
      "[✓] Saved: outputs\\file2_pages\\page_4.png\n",
      "[✓] Saved: outputs\\file2_pages\\page_5.png\n",
      "[✓] Saved: outputs\\file2_pages\\page_6.png\n",
      "[✓] Saved: outputs\\file2_pages\\page_7.png\n",
      "[✓] Saved: outputs\\file2_pages\\page_8.png\n",
      "[✓] Saved: outputs\\file2_pages\\page_9.png\n",
      "[✓] Saved: outputs\\file2_pages\\page_10.png\n",
      "[✓] Saved: outputs\\file2_pages\\page_11.png\n",
      "[✓] Saved: outputs\\file2_pages\\page_12.png\n",
      "[✓] Saved: outputs\\file2_pages\\page_13.png\n",
      "[✓] Saved: outputs\\file2_pages\\page_14.png\n",
      "[✓] Saved: outputs\\file2_pages\\page_15.png\n",
      "[✓] Saved: outputs\\file2_pages\\page_16.png\n",
      "[✓] Saved: outputs\\file2_pages\\page_17.png\n",
      "[✓] Saved: outputs\\file2_pages\\page_18.png\n",
      "[✓] Saved: outputs\\file2_pages\\page_19.png\n",
      "[✓] Saved: outputs\\file2_pages\\page_20.png\n",
      "[✓] Saved: outputs\\file2_pages\\page_21.png\n",
      "[✓] Saved: outputs\\file2_pages\\page_22.png\n",
      "[✓] Saved: outputs\\file2_pages\\page_23.png\n",
      "[✓] Saved: outputs\\file2_pages\\page_24.png\n",
      "[✓] Saved: outputs\\file2_pages\\page_25.png\n",
      "[✓] Saved: outputs\\file2_pages\\page_26.png\n",
      "[✓] Saved: outputs\\file2_pages\\page_27.png\n",
      "[✓] Saved: outputs\\file2_pages\\page_28.png\n",
      "[✓] Saved: outputs\\file2_pages\\page_29.png\n",
      "[✓] Saved: outputs\\file2_pages\\page_30.png\n",
      "[✓] Saved: outputs\\file2_pages\\page_31.png\n",
      "[✓] Saved: outputs\\file2_pages\\page_32.png\n",
      "[✓] Saved: outputs\\file2_pages\\page_33.png\n",
      "[✓] Saved: outputs\\file2_pages\\page_34.png\n",
      "[✓] Saved: outputs\\file2_pages\\page_35.png\n",
      "[*] Running OCR on page images...\n",
      "[✓] OCR saved: outputs\\file2_ocr\\page_1.txt\n",
      "[✓] OCR saved: outputs\\file2_ocr\\page_10.txt\n",
      "[✓] OCR saved: outputs\\file2_ocr\\page_11.txt\n",
      "[✓] OCR saved: outputs\\file2_ocr\\page_12.txt\n",
      "[✓] OCR saved: outputs\\file2_ocr\\page_13.txt\n",
      "[✓] OCR saved: outputs\\file2_ocr\\page_14.txt\n",
      "[✓] OCR saved: outputs\\file2_ocr\\page_15.txt\n",
      "[✓] OCR saved: outputs\\file2_ocr\\page_16.txt\n",
      "[✓] OCR saved: outputs\\file2_ocr\\page_17.txt\n",
      "[✓] OCR saved: outputs\\file2_ocr\\page_18.txt\n",
      "[✓] OCR saved: outputs\\file2_ocr\\page_19.txt\n",
      "[✓] OCR saved: outputs\\file2_ocr\\page_2.txt\n",
      "[✓] OCR saved: outputs\\file2_ocr\\page_20.txt\n",
      "[✓] OCR saved: outputs\\file2_ocr\\page_21.txt\n",
      "[✓] OCR saved: outputs\\file2_ocr\\page_22.txt\n",
      "[✓] OCR saved: outputs\\file2_ocr\\page_23.txt\n",
      "[✓] OCR saved: outputs\\file2_ocr\\page_24.txt\n",
      "[✓] OCR saved: outputs\\file2_ocr\\page_25.txt\n",
      "[✓] OCR saved: outputs\\file2_ocr\\page_26.txt\n",
      "[✓] OCR saved: outputs\\file2_ocr\\page_27.txt\n",
      "[✓] OCR saved: outputs\\file2_ocr\\page_28.txt\n",
      "[✓] OCR saved: outputs\\file2_ocr\\page_29.txt\n",
      "[✓] OCR saved: outputs\\file2_ocr\\page_3.txt\n",
      "[✓] OCR saved: outputs\\file2_ocr\\page_30.txt\n",
      "[✓] OCR saved: outputs\\file2_ocr\\page_31.txt\n",
      "[✓] OCR saved: outputs\\file2_ocr\\page_32.txt\n",
      "[✓] OCR saved: outputs\\file2_ocr\\page_33.txt\n",
      "[✓] OCR saved: outputs\\file2_ocr\\page_34.txt\n",
      "[✓] OCR saved: outputs\\file2_ocr\\page_35.txt\n",
      "[✓] OCR saved: outputs\\file2_ocr\\page_4.txt\n",
      "[✓] OCR saved: outputs\\file2_ocr\\page_5.txt\n",
      "[✓] OCR saved: outputs\\file2_ocr\\page_6.txt\n",
      "[✓] OCR saved: outputs\\file2_ocr\\page_7.txt\n",
      "[✓] OCR saved: outputs\\file2_ocr\\page_8.txt\n",
      "[✓] OCR saved: outputs\\file2_ocr\\page_9.txt\n",
      "[✓] Finished processing file2.pdf\n",
      "\n",
      "[*] Processing file3.pdf...\n",
      "[✓] Text extracted to outputs\\file3_extracted_text.txt\n",
      "[*] Converting PDF to images using PyMuPDF...\n",
      "[✓] Saved: outputs\\file3_pages\\page_1.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_2.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_3.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_4.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_5.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_6.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_7.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_8.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_9.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_10.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_11.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_12.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_13.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_14.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_15.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_16.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_17.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_18.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_19.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_20.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_21.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_22.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_23.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_24.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_25.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_26.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_27.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_28.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_29.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_30.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_31.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_32.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_33.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_34.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_35.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_36.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_37.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_38.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_39.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_40.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_41.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_42.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_43.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_44.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_45.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_46.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_47.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_48.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_49.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_50.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_51.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_52.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_53.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_54.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_55.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_56.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_57.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_58.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_59.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_60.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_61.png\n",
      "[✓] Saved: outputs\\file3_pages\\page_62.png\n",
      "[*] Running OCR on page images...\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_1.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_10.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_11.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_12.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_13.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_14.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_15.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_16.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_17.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_18.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_19.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_2.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_20.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_21.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_22.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_23.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_24.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_25.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_26.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_27.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_28.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_29.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_3.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_30.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_31.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_32.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_33.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_34.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_35.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_36.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_37.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_38.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_39.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_4.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_40.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_41.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_42.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_43.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_44.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_45.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_46.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_47.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_48.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_49.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_5.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_50.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_51.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_52.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_53.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_54.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_55.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_56.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_57.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_58.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_59.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_6.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_60.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_61.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_62.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_7.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_8.txt\n",
      "[✓] OCR saved: outputs\\file3_ocr\\page_9.txt\n",
      "[✓] Finished processing file3.pdf\n",
      "\n",
      "[✓] All PDFs processed successfully.\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import pytesseract\n",
    "import os\n",
    "\n",
    "# ----------- STEP 1: Setup Paths ----------- \n",
    "PDF_FOLDER = \"data\"  # Data folder containing the PDF files\n",
    "BASE_OUTPUT_DIR = \"outputs\"  # Fixed output directory name\n",
    "\n",
    "# Ensure the base output directory exists, and it is a directory (not a file)\n",
    "if not os.path.exists(BASE_OUTPUT_DIR):\n",
    "    os.makedirs(BASE_OUTPUT_DIR, exist_ok=True)\n",
    "elif os.path.isfile(BASE_OUTPUT_DIR):\n",
    "    print(f\"[Error] {BASE_OUTPUT_DIR} exists as a file, but it should be a directory. Exiting...\")\n",
    "    exit()\n",
    "\n",
    "# ----------- STEP 2: Process Each PDF ----------- \n",
    "pdf_files = [f for f in os.listdir(PDF_FOLDER) if f.lower().endswith('.pdf')]  # List all PDF files in the data folder\n",
    "\n",
    "if not pdf_files:\n",
    "    print(\"No PDF files found in the 'data' folder. Exiting...\")\n",
    "    exit()\n",
    "\n",
    "# Process each PDF file one by one\n",
    "for pdf_file in pdf_files:\n",
    "    print(f\"[*] Processing {pdf_file}...\")\n",
    "\n",
    "    # Setup file-specific paths\n",
    "    PDF_PATH = os.path.join(PDF_FOLDER, pdf_file)\n",
    "    IMAGE_DIR = os.path.join(BASE_OUTPUT_DIR, f\"{os.path.splitext(pdf_file)[0]}_pages\")\n",
    "    OCR_DIR = os.path.join(BASE_OUTPUT_DIR, f\"{os.path.splitext(pdf_file)[0]}_ocr\")\n",
    "    TEXT_PATH = os.path.join(BASE_OUTPUT_DIR, f\"{os.path.splitext(pdf_file)[0]}_extracted_text.txt\")\n",
    "\n",
    "    # Ensure that the specific subdirectories for this PDF are created\n",
    "    os.makedirs(IMAGE_DIR, exist_ok=True)\n",
    "    os.makedirs(OCR_DIR, exist_ok=True)\n",
    "\n",
    "    # ----------- STEP 2.1: Extract Text with PyMuPDF ----------- \n",
    "    doc = fitz.open(PDF_PATH)\n",
    "    all_text = \"\"\n",
    "\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        text = page.get_text()\n",
    "        all_text += f\"\\n--- Page {page_num + 1} ---\\n{text}\"\n",
    "\n",
    "    # Save extracted text\n",
    "    with open(TEXT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(all_text)\n",
    "\n",
    "    print(f\"[✓] Text extracted to {TEXT_PATH}\")\n",
    "\n",
    "    # ----------- STEP 2.2: Convert PDF to Images using PyMuPDF ----------- \n",
    "    print(\"[*] Converting PDF to images using PyMuPDF...\")\n",
    "    \n",
    "    for i in range(len(doc)):\n",
    "        page = doc.load_page(i)\n",
    "        pix = page.get_pixmap()  # This is the image representation of the page\n",
    "\n",
    "        # Save image as PNG\n",
    "        img_path = os.path.join(IMAGE_DIR, f\"page_{i + 1}.png\")\n",
    "        pix.save(img_path)\n",
    "        print(f\"[✓] Saved: {img_path}\")\n",
    "\n",
    "    # ----------- STEP 2.3: OCR on Each Page Image ----------- \n",
    "    print(\"[*] Running OCR on page images...\")\n",
    "\n",
    "    for img_file in os.listdir(IMAGE_DIR):\n",
    "        img_path = os.path.join(IMAGE_DIR, img_file)\n",
    "        text = pytesseract.image_to_string(img_path)\n",
    "        \n",
    "        ocr_file = os.path.join(OCR_DIR, img_file.replace(\".png\", \".txt\"))\n",
    "        with open(ocr_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(text)\n",
    "        \n",
    "        print(f\"[✓] OCR saved: {ocr_file}\")\n",
    "\n",
    "    print(f\"[✓] Finished processing {pdf_file}\\n\")\n",
    "\n",
    "print(\"[✓] All PDFs processed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8b6831c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Thorfin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Processing file1.pdf for embeddings...\n",
      "[✓] Saved text embeddings to outputs/embeddings\\file1_text_embeddings.npy\n",
      "[✓] Processed image: page_1.png\n",
      "[✓] Processed image: page_10.png\n",
      "[✓] Processed image: page_11.png\n",
      "[✓] Processed image: page_12.png\n",
      "[✓] Processed image: page_13.png\n",
      "[✓] Processed image: page_14.png\n",
      "[✓] Processed image: page_15.png\n",
      "[✓] Processed image: page_16.png\n",
      "[✓] Processed image: page_17.png\n",
      "[✓] Processed image: page_18.png\n",
      "[✓] Processed image: page_19.png\n",
      "[✓] Processed image: page_2.png\n",
      "[✓] Processed image: page_20.png\n",
      "[✓] Processed image: page_21.png\n",
      "[✓] Processed image: page_22.png\n",
      "[✓] Processed image: page_23.png\n",
      "[✓] Processed image: page_24.png\n",
      "[✓] Processed image: page_25.png\n",
      "[✓] Processed image: page_26.png\n",
      "[✓] Processed image: page_27.png\n",
      "[✓] Processed image: page_28.png\n",
      "[✓] Processed image: page_29.png\n",
      "[✓] Processed image: page_3.png\n",
      "[✓] Processed image: page_30.png\n",
      "[✓] Processed image: page_31.png\n",
      "[✓] Processed image: page_32.png\n",
      "[✓] Processed image: page_33.png\n",
      "[✓] Processed image: page_34.png\n",
      "[✓] Processed image: page_35.png\n",
      "[✓] Processed image: page_36.png\n",
      "[✓] Processed image: page_37.png\n",
      "[✓] Processed image: page_38.png\n",
      "[✓] Processed image: page_39.png\n",
      "[✓] Processed image: page_4.png\n",
      "[✓] Processed image: page_40.png\n",
      "[✓] Processed image: page_41.png\n",
      "[✓] Processed image: page_42.png\n",
      "[✓] Processed image: page_43.png\n",
      "[✓] Processed image: page_44.png\n",
      "[✓] Processed image: page_45.png\n",
      "[✓] Processed image: page_46.png\n",
      "[✓] Processed image: page_47.png\n",
      "[✓] Processed image: page_48.png\n",
      "[✓] Processed image: page_49.png\n",
      "[✓] Processed image: page_5.png\n",
      "[✓] Processed image: page_50.png\n",
      "[✓] Processed image: page_51.png\n",
      "[✓] Processed image: page_52.png\n",
      "[✓] Processed image: page_53.png\n",
      "[✓] Processed image: page_54.png\n",
      "[✓] Processed image: page_55.png\n",
      "[✓] Processed image: page_56.png\n",
      "[✓] Processed image: page_57.png\n",
      "[✓] Processed image: page_58.png\n",
      "[✓] Processed image: page_59.png\n",
      "[✓] Processed image: page_6.png\n",
      "[✓] Processed image: page_60.png\n",
      "[✓] Processed image: page_61.png\n",
      "[✓] Processed image: page_62.png\n",
      "[✓] Processed image: page_63.png\n",
      "[✓] Processed image: page_64.png\n",
      "[✓] Processed image: page_65.png\n",
      "[✓] Processed image: page_66.png\n",
      "[✓] Processed image: page_67.png\n",
      "[✓] Processed image: page_68.png\n",
      "[✓] Processed image: page_69.png\n",
      "[✓] Processed image: page_7.png\n",
      "[✓] Processed image: page_70.png\n",
      "[✓] Processed image: page_71.png\n",
      "[✓] Processed image: page_72.png\n",
      "[✓] Processed image: page_73.png\n",
      "[✓] Processed image: page_74.png\n",
      "[✓] Processed image: page_75.png\n",
      "[✓] Processed image: page_76.png\n",
      "[✓] Processed image: page_77.png\n",
      "[✓] Processed image: page_78.png\n",
      "[✓] Processed image: page_79.png\n",
      "[✓] Processed image: page_8.png\n",
      "[✓] Processed image: page_80.png\n",
      "[✓] Processed image: page_81.png\n",
      "[✓] Processed image: page_82.png\n",
      "[✓] Processed image: page_83.png\n",
      "[✓] Processed image: page_84.png\n",
      "[✓] Processed image: page_85.png\n",
      "[✓] Processed image: page_9.png\n",
      "[✓] Saved image embeddings to outputs/embeddings\\file1_image_embeddings.npy\n",
      "[✓] Finished processing file1.pdf for embeddings.\n",
      "\n",
      "[*] Processing file2.pdf for embeddings...\n",
      "[✓] Saved text embeddings to outputs/embeddings\\file2_text_embeddings.npy\n",
      "[✓] Processed image: page_1.png\n",
      "[✓] Processed image: page_10.png\n",
      "[✓] Processed image: page_11.png\n",
      "[✓] Processed image: page_12.png\n",
      "[✓] Processed image: page_13.png\n",
      "[✓] Processed image: page_14.png\n",
      "[✓] Processed image: page_15.png\n",
      "[✓] Processed image: page_16.png\n",
      "[✓] Processed image: page_17.png\n",
      "[✓] Processed image: page_18.png\n",
      "[✓] Processed image: page_19.png\n",
      "[✓] Processed image: page_2.png\n",
      "[✓] Processed image: page_20.png\n",
      "[✓] Processed image: page_21.png\n",
      "[✓] Processed image: page_22.png\n",
      "[✓] Processed image: page_23.png\n",
      "[✓] Processed image: page_24.png\n",
      "[✓] Processed image: page_25.png\n",
      "[✓] Processed image: page_26.png\n",
      "[✓] Processed image: page_27.png\n",
      "[✓] Processed image: page_28.png\n",
      "[✓] Processed image: page_29.png\n",
      "[✓] Processed image: page_3.png\n",
      "[✓] Processed image: page_30.png\n",
      "[✓] Processed image: page_31.png\n",
      "[✓] Processed image: page_32.png\n",
      "[✓] Processed image: page_33.png\n",
      "[✓] Processed image: page_34.png\n",
      "[✓] Processed image: page_35.png\n",
      "[✓] Processed image: page_4.png\n",
      "[✓] Processed image: page_5.png\n",
      "[✓] Processed image: page_6.png\n",
      "[✓] Processed image: page_7.png\n",
      "[✓] Processed image: page_8.png\n",
      "[✓] Processed image: page_9.png\n",
      "[✓] Saved image embeddings to outputs/embeddings\\file2_image_embeddings.npy\n",
      "[✓] Finished processing file2.pdf for embeddings.\n",
      "\n",
      "[*] Processing file3.pdf for embeddings...\n",
      "[✓] Saved text embeddings to outputs/embeddings\\file3_text_embeddings.npy\n",
      "[✓] Processed image: page_1.png\n",
      "[✓] Processed image: page_10.png\n",
      "[✓] Processed image: page_11.png\n",
      "[✓] Processed image: page_12.png\n",
      "[✓] Processed image: page_13.png\n",
      "[✓] Processed image: page_14.png\n",
      "[✓] Processed image: page_15.png\n",
      "[✓] Processed image: page_16.png\n",
      "[✓] Processed image: page_17.png\n",
      "[✓] Processed image: page_18.png\n",
      "[✓] Processed image: page_19.png\n",
      "[✓] Processed image: page_2.png\n",
      "[✓] Processed image: page_20.png\n",
      "[✓] Processed image: page_21.png\n",
      "[✓] Processed image: page_22.png\n",
      "[✓] Processed image: page_23.png\n",
      "[✓] Processed image: page_24.png\n",
      "[✓] Processed image: page_25.png\n",
      "[✓] Processed image: page_26.png\n",
      "[✓] Processed image: page_27.png\n",
      "[✓] Processed image: page_28.png\n",
      "[✓] Processed image: page_29.png\n",
      "[✓] Processed image: page_3.png\n",
      "[✓] Processed image: page_30.png\n",
      "[✓] Processed image: page_31.png\n",
      "[✓] Processed image: page_32.png\n",
      "[✓] Processed image: page_33.png\n",
      "[✓] Processed image: page_34.png\n",
      "[✓] Processed image: page_35.png\n",
      "[✓] Processed image: page_36.png\n",
      "[✓] Processed image: page_37.png\n",
      "[✓] Processed image: page_38.png\n",
      "[✓] Processed image: page_39.png\n",
      "[✓] Processed image: page_4.png\n",
      "[✓] Processed image: page_40.png\n",
      "[✓] Processed image: page_41.png\n",
      "[✓] Processed image: page_42.png\n",
      "[✓] Processed image: page_43.png\n",
      "[✓] Processed image: page_44.png\n",
      "[✓] Processed image: page_45.png\n",
      "[✓] Processed image: page_46.png\n",
      "[✓] Processed image: page_47.png\n",
      "[✓] Processed image: page_48.png\n",
      "[✓] Processed image: page_49.png\n",
      "[✓] Processed image: page_5.png\n",
      "[✓] Processed image: page_50.png\n",
      "[✓] Processed image: page_51.png\n",
      "[✓] Processed image: page_52.png\n",
      "[✓] Processed image: page_53.png\n",
      "[✓] Processed image: page_54.png\n",
      "[✓] Processed image: page_55.png\n",
      "[✓] Processed image: page_56.png\n",
      "[✓] Processed image: page_57.png\n",
      "[✓] Processed image: page_58.png\n",
      "[✓] Processed image: page_59.png\n",
      "[✓] Processed image: page_6.png\n",
      "[✓] Processed image: page_60.png\n",
      "[✓] Processed image: page_61.png\n",
      "[✓] Processed image: page_62.png\n",
      "[✓] Processed image: page_7.png\n",
      "[✓] Processed image: page_8.png\n",
      "[✓] Processed image: page_9.png\n",
      "[✓] Saved image embeddings to outputs/embeddings\\file3_image_embeddings.npy\n",
      "[✓] Finished processing file3.pdf for embeddings.\n",
      "\n",
      "[✓] All embeddings processed and saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Thorfin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Thorfin\\.cache\\huggingface\\hub\\models--openai--clip-vit-base-patch32. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# ----------- STEP 3: Setup Embedding Models -----------\n",
    "\n",
    "# Load the text embedding model (Sentence-BERT)\n",
    "text_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Load the CLIP model and processor for image embeddings\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "# ----------- STEP 3.1: Embedding Text -----------\n",
    "\n",
    "def embed_text(text):\n",
    "    \"\"\"Embed the text using Sentence-BERT\"\"\"\n",
    "    embeddings = text_model.encode([text])  # Returns a list of embeddings\n",
    "    return embeddings[0]  # Extract the embedding for the first sentence (since we have one)\n",
    "\n",
    "# ----------- STEP 3.2: Embedding Images -----------\n",
    "\n",
    "def embed_image(image_path):\n",
    "    \"\"\"Embed the image using CLIP\"\"\"\n",
    "    image = Image.open(image_path)\n",
    "    inputs = clip_processor(images=image, return_tensors=\"pt\", padding=True)\n",
    "    outputs = clip_model.get_image_features(**inputs)\n",
    "    image_embedding = outputs.detach().cpu().numpy()  # Directly use the tensor\n",
    "    return image_embedding\n",
    "\n",
    "\n",
    "# ----------- STEP 3.3: Save the Embeddings for Each PDF -----------\n",
    "\n",
    "# Base output directory for embeddings\n",
    "VECTOR_DIR = \"outputs/embeddings\"\n",
    "os.makedirs(VECTOR_DIR, exist_ok=True)\n",
    "\n",
    "# Process each PDF (we assume you've already extracted text and saved images)\n",
    "PDF_FOLDER = \"data\"\n",
    "BASE_OUTPUT_DIR = \"outputs\"\n",
    "\n",
    "# List all PDF files in the data folder\n",
    "pdf_files = [f for f in os.listdir(PDF_FOLDER) if f.lower().endswith('.pdf')]\n",
    "\n",
    "for pdf_file in pdf_files:\n",
    "    print(f\"[*] Processing {pdf_file} for embeddings...\")\n",
    "\n",
    "    # Define specific directories for each PDF\n",
    "    IMAGE_DIR = os.path.join(BASE_OUTPUT_DIR, f\"{os.path.splitext(pdf_file)[0]}_pages\")\n",
    "    TEXT_PATH = os.path.join(BASE_OUTPUT_DIR, f\"{os.path.splitext(pdf_file)[0]}_extracted_text.txt\")\n",
    "    EMBEDDINGS_TEXT_PATH = os.path.join(VECTOR_DIR, f\"{os.path.splitext(pdf_file)[0]}_text_embeddings.npy\")\n",
    "    EMBEDDINGS_IMAGE_PATH = os.path.join(VECTOR_DIR, f\"{os.path.splitext(pdf_file)[0]}_image_embeddings.npy\")\n",
    "\n",
    "    # ----------- STEP 3.4: Embed and Store Text Embeddings -----------\n",
    "\n",
    "    # Read extracted text\n",
    "    with open(TEXT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        all_text = f.read()\n",
    "\n",
    "    # Embed the text\n",
    "    text_embedding = embed_text(all_text)\n",
    "\n",
    "    # Save text embeddings as a numpy array\n",
    "    np.save(EMBEDDINGS_TEXT_PATH, text_embedding)\n",
    "    print(f\"[✓] Saved text embeddings to {EMBEDDINGS_TEXT_PATH}\")\n",
    "\n",
    "    # ----------- STEP 3.5: Embed and Store Image Embeddings -----------\n",
    "\n",
    "    # List all images in the page directory\n",
    "    image_files = [f for f in os.listdir(IMAGE_DIR) if f.lower().endswith('.png')]\n",
    "    all_image_embeddings = []\n",
    "\n",
    "    for img_file in image_files:\n",
    "        img_path = os.path.join(IMAGE_DIR, img_file)\n",
    "        image_embedding = embed_image(img_path)\n",
    "        all_image_embeddings.append(image_embedding)\n",
    "        print(f\"[✓] Processed image: {img_file}\")\n",
    "\n",
    "    # Convert the list of image embeddings into a numpy array\n",
    "    all_image_embeddings = np.array(all_image_embeddings)\n",
    "\n",
    "    # Save image embeddings as a numpy array\n",
    "    np.save(EMBEDDINGS_IMAGE_PATH, all_image_embeddings)\n",
    "    print(f\"[✓] Saved image embeddings to {EMBEDDINGS_IMAGE_PATH}\")\n",
    "\n",
    "    print(f\"[✓] Finished processing {pdf_file} for embeddings.\\n\")\n",
    "\n",
    "print(\"[✓] All embeddings processed and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1cfb6789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Searching for text query...\n",
      "\n",
      "Top results for text query:\n",
      "Rank 1: PDF File 'file1', Distance 1.9480\n",
      "Rank 2: No valid result found.\n",
      "Rank 3: No valid result found.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "import os\n",
    "from sklearn.preprocessing import normalize\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import torch  # Ensure this is imported for tensor operations\n",
    "\n",
    "# ----------- Configuration ----------- \n",
    "EMBEDDING_FOLDER = \"outputs/embeddings\"\n",
    "\n",
    "# ----------- Load Embeddings ----------- \n",
    "def load_embeddings(file_path):\n",
    "    return np.load(file_path)\n",
    "\n",
    "def get_embedding_files(folder):\n",
    "    return [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith('.npy')]\n",
    "\n",
    "embedding_files = get_embedding_files(EMBEDDING_FOLDER)\n",
    "text_embeddings = [load_embeddings(f) for f in embedding_files if 'text' in f]\n",
    "image_embeddings = [load_embeddings(f) for f in embedding_files if 'image' in f]\n",
    "\n",
    "all_text_embeddings = np.concatenate(text_embeddings, axis=0) if text_embeddings else np.array([])\n",
    "all_image_embeddings = np.concatenate(image_embeddings, axis=0) if image_embeddings else np.array([])\n",
    "\n",
    "if all_text_embeddings.size:\n",
    "    all_text_embeddings = all_text_embeddings.reshape(-1, all_text_embeddings.shape[-1])\n",
    "    all_text_embeddings = normalize(all_text_embeddings)\n",
    "\n",
    "if all_image_embeddings.size:\n",
    "    all_image_embeddings = all_image_embeddings.reshape(-1, all_image_embeddings.shape[-1])\n",
    "    all_image_embeddings = normalize(all_image_embeddings)\n",
    "\n",
    "# ----------- FAISS Indexing ----------- \n",
    "def create_faiss_index(embedding_dim):\n",
    "    return faiss.IndexFlatL2(embedding_dim)\n",
    "\n",
    "embedding_dim_text = all_text_embeddings.shape[1] if all_text_embeddings.size else None\n",
    "embedding_dim_image = all_image_embeddings.shape[1] if all_image_embeddings.size else None\n",
    "\n",
    "if embedding_dim_text and embedding_dim_image and embedding_dim_text != embedding_dim_image:\n",
    "    print(\"[Warning] Text and image embeddings have different dimensions. Creating separate indexes.\")\n",
    "\n",
    "text_index = create_faiss_index(embedding_dim_text) if all_text_embeddings.size else None\n",
    "image_index = create_faiss_index(embedding_dim_image) if all_image_embeddings.size else None\n",
    "\n",
    "if text_index is not None:\n",
    "    text_index.add(all_text_embeddings.astype(np.float32))\n",
    "\n",
    "if image_index is not None:\n",
    "    image_index.add(all_image_embeddings.astype(np.float32))\n",
    "\n",
    "print(\"[✓] FAISS indexes created and embeddings added.\")\n",
    "\n",
    "# ----------- Determine Number of PDFs ----------- \n",
    "num_pdfs = len(set(f.split('_')[0] for f in os.listdir(EMBEDDING_FOLDER) if f.endswith('.npy')))\n",
    "\n",
    "# ----------- Search Function ----------- \n",
    "def search(query_embedding, index, top_k=5):\n",
    "    distances, indices = index.search(query_embedding.astype(np.float32), top_k)\n",
    "    return distances, indices\n",
    "\n",
    "# ----------- Text Embedding Model ----------- \n",
    "text_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# ----------- Image Embedding Model ----------- \n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch16\")\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch16\")\n",
    "\n",
    "def embed_text(query):\n",
    "    # Split query into 3 equal parts for consistent embedding structure\n",
    "    parts = [query[i::3] for i in range(3)]  # Simple split into 3 parts\n",
    "    embeddings = []\n",
    "\n",
    "    for part in parts:\n",
    "        inputs = clip_processor(text=[part], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = clip_model.get_text_features(**inputs)\n",
    "        embeddings.append(outputs.cpu().numpy())\n",
    "\n",
    "    # Concatenate all embeddings (each is (1, 512)) → result (1, 1536)\n",
    "    concatenated = np.concatenate(embeddings, axis=1)\n",
    "\n",
    "    # Truncate to 1152 (if that's what was done during storage)\n",
    "    embedding = concatenated[:, :1152]\n",
    "\n",
    "    return normalize(embedding)\n",
    "\n",
    "def embed_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    inputs = clip_processor(images=image, return_tensors=\"pt\", padding=True)\n",
    "    outputs = clip_model.get_image_features(**inputs)\n",
    "    embedding = outputs.detach().cpu().numpy()\n",
    "    return normalize(embedding)\n",
    "\n",
    "# ----------- Take Query from User ----------- \n",
    "query_type = input(\"Enter query type (text/image): \").strip().lower()\n",
    "\n",
    "if query_type == \"text\":\n",
    "    query_text = input(\"Enter your text query: \")\n",
    "    query_text_embedding = embed_text(query_text)\n",
    "\n",
    "    if query_text_embedding.shape[1] != embedding_dim_text:\n",
    "        raise ValueError(f\"Query embedding dimension {query_text_embedding.shape[1]} does not match index dimension {embedding_dim_text}.\")\n",
    "\n",
    "    if text_index is not None:\n",
    "        top_k = num_pdfs  # Ensure it's the number of PDFs, not just the number of index entries\n",
    "        print(\"[*] Searching for text query...\")\n",
    "        text_distances, text_indices = search(query_text_embedding, text_index, top_k=top_k)\n",
    "\n",
    "        print(\"\\nTop results for text query:\")\n",
    "        found_valid_results = False\n",
    "        for i, (idx, dist) in enumerate(zip(text_indices[0], text_distances[0])):\n",
    "            if idx != -1:  # Check if the result is valid\n",
    "                pdf_name = pdf_names[idx] if idx < len(pdf_names) else \"Unknown PDF\"\n",
    "                print(f\"Rank {i+1}: PDF File '{pdf_name}', Distance {dist:.4f}\")\n",
    "                found_valid_results = True\n",
    "            else:\n",
    "                print(f\"Rank {i+1}: No valid result found.\")\n",
    "        \n",
    "        if not found_valid_results:\n",
    "            print(\"No valid results found for the text query.\")\n",
    "\n",
    "elif query_type == \"image\":\n",
    "    image_path = input(\"Enter path to image query: \").strip()\n",
    "    query_image_embedding = embed_image(image_path)\n",
    "\n",
    "    if query_image_embedding.shape[1] != embedding_dim_image:\n",
    "        raise ValueError(f\"Image embedding dimension {query_image_embedding.shape[1]} does not match index dimension {embedding_dim_image}.\")\n",
    "\n",
    "    if image_index is not None:\n",
    "        top_k = num_pdfs  # Ensure it's the number of PDFs, not just the number of index entries\n",
    "        print(\"[*] Searching for image query...\")\n",
    "        image_distances, image_indices = search(query_image_embedding, image_index, top_k=top_k)\n",
    "\n",
    "        print(\"\\nTop results for image query:\")\n",
    "        found_valid_results = False\n",
    "        for i, (idx, dist) in enumerate(zip(image_indices[0], image_distances[0])):\n",
    "            if idx != -1:  # Check if the result is valid\n",
    "                pdf_name = pdf_names[idx] if idx < len(pdf_names) else \"Unknown PDF\"\n",
    "                print(f\"Rank {i+1}: PDF File '{pdf_name}', Distance {dist:.4f}\")\n",
    "                found_valid_results = True\n",
    "            else:\n",
    "                print(f\"Rank {i+1}: No valid result found.\")\n",
    "        \n",
    "        if not found_valid_results:\n",
    "            print(\"No valid results found for the image query.\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Invalid query type. Please enter 'text' or 'image'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3ae73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "from google import genai\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Set your API key for Gemini\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = 'AIzaSyC89YzwZQEzKiFCl-8tz8PIxXTUvD8RzQM'\n",
    "\n",
    "# Initialize the Gemini client\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# ----------- Function to Generate Text Using Gemini ----------- #\n",
    "def generate_text_from_gemini(query, retrieved_docs):\n",
    "    \"\"\"\n",
    "    Generate a response using Gemini by combining the query and retrieved documents.\n",
    "    \n",
    "    Args:\n",
    "    - query (str): The user's query or question.\n",
    "    - retrieved_docs (list of str): List of retrieved documents (context) from the database.\n",
    "    \n",
    "    Returns:\n",
    "    - response (str): The generated response based on the query and context.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Combine the query with the retrieved documents to form a context string\n",
    "    context = \"\\n\".join(retrieved_docs)  # Join documents into a single context string\n",
    "    prompt = f\"Query: {query}\\nContext:\\n{context}\\nAnswer:\"\n",
    "\n",
    "    try:\n",
    "        # Generate content using Gemini API\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.5-pro-exp-03-25\",  # Replace with the appropriate model name if different\n",
    "            contents=prompt\n",
    "        )\n",
    "        \n",
    "        # Extract the generated text from the response\n",
    "        generated_text = response.text.strip() if response.text else 'Error: No valid response.'\n",
    "        return generated_text\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating text: {e}\")\n",
    "        return \"Error generating response.\"\n",
    "\n",
    "# ----------- Function to Extract Text from PDF Files ----------- #\n",
    "def get_pdf_text(pdf_docs):\n",
    "    \"\"\"Extract text from PDF files\"\"\"\n",
    "    text = \"\"\n",
    "    for pdf in pdf_docs:\n",
    "        pdf_reader = PdfReader(pdf)\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text() or \"\"  \n",
    "    return text\n",
    "\n",
    "# ----------- Function to Split Text into Chunks ----------- #\n",
    "def get_text_chunks(text):\n",
    "    \"\"\"Split text into chunks for better processing\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=15000, chunk_overlap=100)\n",
    "    return text_splitter.split_text(text)\n",
    "\n",
    "# ----------- Function to Load All .txt Files from Outputs/ ----------- #\n",
    "def load_text_from_file(file_path):\n",
    "    \"\"\"Load text content from a file\"\"\"\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    return \"\"\n",
    "\n",
    "# ----------- Streamlit UI Setup ----------- #\n",
    "st.title(\"RAG Bot: Ask Questions from PDF Documents\")\n",
    "st.markdown(\"\"\"\n",
    "    Upload multiple PDF files, and the bot will answer your questions based on the content.\n",
    "    \"\"\")\n",
    "\n",
    "# File uploader for PDFs\n",
    "pdf_docs = st.file_uploader(\"Upload Your PDF Files\", accept_multiple_files=True, type=\"pdf\", key=\"pdf_uploader\")\n",
    "\n",
    "if pdf_docs:\n",
    "    with st.spinner(\"Processing PDFs...\"):\n",
    "        # Extract and process text from PDFs\n",
    "        extracted_text = get_pdf_text(pdf_docs)\n",
    "        text_chunks = get_text_chunks(extracted_text)\n",
    "        \n",
    "        # Save extracted text to the outputs/ directory\n",
    "        output_dir = 'outputs/'\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        extracted_file_path = os.path.join(output_dir, \"extracted_text.txt\")\n",
    "        with open(extracted_file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(extracted_text)\n",
    "        \n",
    "        st.success(\"PDFs processed successfully!\")\n",
    "\n",
    "# Fetch documents for RAG from all extracted_text.txt files in the outputs/ directory\n",
    "output_dir = 'outputs/'\n",
    "retrieved_docs = []\n",
    "for filename in os.listdir(output_dir):\n",
    "    if filename.endswith(\"extracted_text.txt\"):\n",
    "        file_path = os.path.join(output_dir, filename)\n",
    "        retrieved_docs.append(load_text_from_file(file_path))\n",
    "\n",
    "# User question input\n",
    "user_query = st.text_input(\"Ask a question related to the uploaded documents:\")\n",
    "\n",
    "# When the user asks a question\n",
    "if user_query and retrieved_docs:\n",
    "    with st.spinner(\"Generating response...\"):\n",
    "        # Generate response using Gemini\n",
    "        response = generate_text_from_gemini(user_query, retrieved_docs)\n",
    "        \n",
    "        # Display the response\n",
    "        st.write(\"### Answer:\")\n",
    "        st.write(response)\n",
    "\n",
    "# If no PDFs are uploaded\n",
    "if not pdf_docs:\n",
    "    st.warning(\"Please upload one or more PDF files to get started.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0734110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "def evaluate_bleu_rouge(generated_response, reference_response):\n",
    "    \"\"\"\n",
    "    Evaluate BLEU and ROUGE scores for the generated response.\n",
    "\n",
    "    Args:\n",
    "    - generated_response (str): Response generated by the system.\n",
    "    - reference_response (str): Ideal/reference response.\n",
    "\n",
    "    Returns:\n",
    "    - dict: BLEU and ROUGE scores.\n",
    "    \"\"\"\n",
    "    # BLEU Score\n",
    "    bleu_score = sentence_bleu(\n",
    "        [reference_response.split()],  # Reference is tokenized\n",
    "        generated_response.split()     # Generated response is tokenized\n",
    "    )\n",
    "\n",
    "    # ROUGE Scores\n",
    "    rouge = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    rouge_scores = rouge.score(reference_response, generated_response)\n",
    "\n",
    "    return {\n",
    "        \"BLEU\": bleu_score,\n",
    "        \"ROUGE-1\": rouge_scores['rouge1'].fmeasure,\n",
    "        \"ROUGE-2\": rouge_scores['rouge2'].fmeasure,\n",
    "        \"ROUGE-L\": rouge_scores['rougeL'].fmeasure\n",
    "    }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
